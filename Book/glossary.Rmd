\cleardoublepage 

# (APPENDIX) Appendix {-}

# Glossaire des termes{.tabset}

Ci-dessous voici les termes principaux, fréquemment utilisés dans le livre et plus généralement à travers les discussions d'expériences de terrain aléatoires.

## Concepts clés

Voir le module sur [l'inférence causale](causal-inference.html), [les estimandes et les estimateurs](estimands-and-estimators.html).

- **Résultat potentiel $Y_i(T)$** Le résultat $Y$ que l'unité $i$ *aurait* sous la condition de traitement $T$.  Ceux-ci sont considérés comme des quantités fixes pour un moment précis.  $T$ peut être 0 pour le contrôle ou 1 pour le traitement s'il n'y a qu'un seul type de traitement. Voir le module sur [l'inférence causale](causal-inference.html).
- **Effet du traitement $\tau_i$ pour l'unité $i$** Le contraste entre les résultats potentiels sous deux conditions de traitement pour l'unité $i$.  L'effet du traitement est généralement défini comme la différence entre les résultats potentiels sous traitement et sous contrôle, $Y_i(1)-Y_i(0)$.  Voir le module sur [l'inférence causale](causal-inference.html).
- **Problème fondamental de l'inférence causale** dans le framework contrefactuel.  On ne peut pas observer à la fois $Y_i(1)$ et $Y_i(0)$ pour une unité donnée, donc on ne peut pas obtenir $\tau_i$ directement. Voir le module sur [l'inférence causale](causal-inference.html).
- **Estimande** Ce que vous visez à estimer.  Un exemple d'un estimande est l'effet moyen du traitement. Dans l'inférence causale contrefactuelle, l'effet moyen du traitement est fonction des résultats potentiels, et non des résultats observés. Voir le module sur [les estimandes et les estimateurs](estimands-and-estimators.html).
- **Estimateur** Comment on devine la valeur de son estimande à partir des données dont on dispose
 (les données observées).  Un exemple d'estimateur est la différence des moyennes. Voir le module sur [les estimandes et les estimateurs](estimands-and-estimators.html).
  - **L'effet moyen du traitement (Average treatment effect, ATE)** La moyenne de l'effet du traitement pour tous les individus de votre groupe de sujets.  C'est un type d'**estimande**.  Si on définit $\tau_i$ comme étant $Y_i(1)-Y_i(0)$, alors l'effet moyen du traitement est $\overline{Y_i(1)-Y_i(0)}$, ce qui équivaut aussi à $\overline{{Y}_i(1)}-\overline{{Y}_i(0)}$. Notez qu'on n'utilise pas le style de notation$E[Y_i (1)]$ ice parce que $E[]$ signifie "moyenne sur des opérations répétées," mais $\overline{Y}$ signifie "moyenne sur un ensemble d'observations". Voir le module sur [l'inférence causale](causal-inference.html) et le module sur [les estimandes et les estimateurs](estimands-and-estimators.html).
- **Échantillonnage aléatoire** Sélection de sujets dans une population avec des probabilités connues strictement comprises entre 0 et 1.
- **Une experience avec $k$ bras de traitement** Une experience qui comprend $k$ conditions de traitement
  (y compris le contrôle). Voir le module sur [la randomisation](randomization.html).
- **Assignation aléatoire** Assignation des sujets à des conditions expérimentales avec des probabilités connues strictement comprises entre 0 et 1.  Cela équivaut à un échantillonnage aléatoire sans remise à partir des résultats potentiels.  Il existe plusieurs stratégies d'assignation aléatoire: simple, complète, par grappe (cluster), par bloc, TODO blocked-cluster. Voir le module sur [la randomisation](randomization.html).
- **Validité externe** Les résultats de votre étude vous renseignent sur des contextes en dehors de votre échantillon --- dans d'autres endroits ou pour d'autres interventions.

## Inférence statistique

Voir les modules sur [les tests d'hypothèses](hypothesis-testing.html) et [la puissance statistique](statistical-power-and-design-diagnosands.html).

- **Hypothèse** Une affirmation simple, claire et falsifiable sur le monde. Dans l'inférence causale contrefactuelle, une hypothèse est une déclaration sur une relation
  parmi les résultats potentiels, comme $H_0: Y_i(T_i=0) = Y_i(T_i=1) + \tau_i$ pour
  l'hypothèse que le résultat potentiel sous traitement est le
  résultat potentiel sous contrôle plus un certain effet pour chaque unité $i$. Voir le
  module sur [les tests d'hypothèses](hypothesis-testing.html).
- **Hypothèse nulle**  Une conjecture sur le monde que vous pouvez rejeter après
  voir les données.  Voir le module sur [les tests d'hypothèses](hypothesis-testing.html).
- **TODO Sharp null hypothesis of no effect** L'hypothèse nulle selon laquelle il n'y a aucun effet du traitement pour aucun sujet.  Cela signifie $Y_i(1)=Y_i(0)$ pour tout $i$. On pourrait écrire ceci comme $H_0: Y_i(T_i=0) = Y_i(T_i=1)$.  Voir le module sur [les tests d'hypothèses](hypothesis-testing.html).
- **$p$-valeur** La probabilité de voir une statistique de test aussi grande (en valeur absolue) ou plus grande que la statistique de test calculée à partir des données observées.  Voir le module sur [les tests d'hypothèses](hypothesis-testing.html).
- **One-sided vs. two-sided test** When you have a strong expectation that the
  effect is either positive or negative, you can conduct a one-sided test.
  When you do not have such a strong expectation, conduct a two-sided test.  A
  one-sided test has more power than a two-sided test for the same experiment.
  Voir le module sur [les tests d'hypothèses](hypothesis-testing.html).
- **Standard deviation** Square root of the mean-square deviation from the average of a variable.  C'est une mesure de la dispersion ou de la propagation d'une statistique.
  $SD_x=\sqrt{\frac{1}{n}\sum_{i=1}^n(x_i-\bar{x})^2}$
- **False Positive Rate/Type I Error of a Test** A well-operating hypothesis
  test rejects a hypothesis about a true causal effect no more than $\alpha$ %
  of the time. The false positive rate is the rate at which a test will cast
  doubt on a true hypothesis.  It is the rate at which the test will encourage the analyst to say "statistically significant" when, in fact, there is no causal relationship. Voir le module sur [les tests d'hypothèses](hypothesis-testing.html).
- **Sampling distribution** The distribution of estimates (e.g., estimates of the ATE) for all possible treatment assignments. In design-based statistical inference for randomized experiments, the distribution of estimates from an estimator is generated from randomizations. Many call this a "sampling distribution" because textbooks often use the idea of repeated samples from a population rather than repeated randomizations to describe this kind of variation.
- **Standard error** L'écart type de la distribution d'échantillonnage. A bigger standard error means that our estimates are more susceptible to sampling variation. Voir le module sur [estimands and estimators](estimands-and-estimators.html).
- **Coverage of a confidence interval** A well-operating confidence interval
  contains the true causal effect $100 ( 1 - \alpha)$ % of the time. A
  confidence interval has *incorrect coverage* when it excludes the true
  parameter less than $100 (1 - \alpha)$% of the time.  For example, a 95%
  confidence interval is supposed to only exclude the true parameter less than
  5% of the time.
- **Statistical power of a test**  Probability that a test of causal effects
  will detect a statistically significant treatment effect if the effect
  exists. Voir le module sur [statistical power](statistical-power-and-design-diagnosands.html). This depends on:
    -  The number of observations in each arm of the experiment
    -  Effect size (usually measured in standardized units)
    -  Noisiness of the outcome variable
    -  Significance level ($\alpha$, which is fixed by convention)
    -  Other factors including what proportion of your units are assigned to
    different treatment conditions.
- **Intra-cluster correlation** How correlated the potential outcomes of units
  are within clusters compared to across clusters.  Higher intra-cluster
  correlation hurts power.
- **Unbiased** An estimator is unbiased if you *expect* that it will return the
  right outcome. That means that if you were to run the experiment many times,
  the estimate might be too high or to low sometimes but it will be right on
  average. Voir le module sur [estimands and estimators](estimands-and-estimators.html).
- **Bias** Bias is the difference between the average value of the estimator
  across its sampling distribution and the single, fixed value of the estimand. Voir le module sur [estimands and estimators](estimands-and-estimators.html).
- **Consistency of an estimator** An estimator that produces answers that
  become ever nearer to the true value of the estimand as the sample size increases is a *consistent estimator* of that estimand. A consistent estimator may or may not be unbiased. Voir le module sur [estimands and estimators](estimands-and-estimators.html).
- **Precision/Efficiency of an estimator** The variation in or width of the
  sampling distribution of an estimator. Voir le module sur [estimands and estimators](estimands-and-estimators.html).



## Stratégies de randomisation

Voir le module sur [la randomisation](randomization.html).

- **Simple** An independent coin flip for each unit.  You are not guaranteed
  that your experiment will have a specific number of treated units.
- **Complete** Assign $m$ out of $N$ units to treatment.  You know how
  many units will be treated in your experiment and each unit has a $m/N$
  probability of being treated.  The number of ways treatment can be assigned
  (number of permutations of treatment assignment) is $\frac{N!}{m!(N-m)!}$.
- **Block** First divide the sample into blocks, then do complete randomization separately in each block.  A block is a set of units within which you conduct random assignment.
- **Cluster** Clusters of units are randomly assigned to treatment conditions.
  A cluster is a set of units that will always be assigned to the same
  treatment status.
- **Blocked-Cluster**  First form blocks of clusters.  Then in each block,
  randomly assign the clusters to treatment conditions using complete
  randomization.

## Factorial Designs

Voir le module sur [la randomisation](randomization.html).

- **Factorial design** A design with more than one treatment, with each
  treatment assigned independently.  The simplest factorial design is a 2 by 2.
- **Conditional marginal effect**  The effect of one treatment, conditional on
  the other being held at a fixed value. For example:
  $Y_i(T_1=1|T_2=0)-Y_i(T_1=0|T_2=0)$ is the marginal effect of $T_1$
  conditional on $T_2=0$.
- **Average marginal effect**  Main effect of each treatment in a factorial
  design.  It is the average of the conditional marginal effects for all the
  conditions of the other treatment, weighted by the proportion of the sample
  that was assigned to each condition.
- **Interaction effect** In a factorial design, we may also estimate
  interaction effects.
    - No interaction effect: one treatment does not amplify or reduce the
    effect of the other treatment.
    - Multiplicative interaction effect:  the effect of one treatment depends on which condition a unit was assigned for the other treatment.  This means one treatment *does* amplify or reduce the effect of the other.  The effect of two treatments together is *not* the sum of the effect of each treatment.

## Threats

Voir le module sur [threats](threats-to-internal-validity-of-randomized-experiments.html).

- **Hawthorne effect** When a subject responds to being observed.
- **Spillover** When a subject responds to another subject's treatment status.
  Example: my health depends on whether my neighbor is vaccinated, as well as
  whether I am vaccinated.
- **Attrition** When outcomes for some subjects are not measured.  This might be caused, for example, by people migrating, refusing to respond to endline surveys, or dying.  This is especially problematic for inference when it is correlated with treatment status.
- **Compliance** A unit's treatment status matches its assigned treatment
  condition.  Example of non-compliance: a unit assigned to treatment doesn't
  take it. Example of compliance: a unit assigned to control does not take
  treatment.
- **Compliance types**  There are four types of units in terms of compliance:
     - **Compliers** Units that would take treatment if assigned to treatment and would be untreated if assigned to control.
     - **Always-takers** Units that would take treatment if assigned to treatment and if assigned to control.
     - **Never-takers** Units that would be untreated if assigned to treatment and if assigned to control.
     - **Defiers** Units that would be untreated if assigned to treatment and
    would take treatment if assigned to control.
- **One-sided non-compliance** The experiment has only compliers and
  *either* always-takers or never-takers.  Usually, we think of
  one-sided non-compliance as having only never-takers and compliers, meaning
  that that local average treatment effect is the effect of treatment on the
  treated.
- **Two-sided non-compliance** The experiment may have all four latent groups.
- **Encouragement design**  An experiment that randomizes $T$ (treatment
  assignment), and we measure $D$ (whether the unit takes treatment) and $Y$
  (outcome).  We can estimate the ITT and the LATE (local average treatment
  effect, aka CACE---complier average causal effect).  It requires three
  assumptions.
     - **Monotonicity**  Assumption of either no defiers or no compliers.  Usually we assume no defiers which means that the effect of assignment on take up of treatment is either positive or zero but not negative.
     - **First stage** Assumption that there is an effect of $T$ on $D$.
     - **Exclusion restriction** Assumption that $T$ affects $Y$ only through $D$. This is usually the most problematic assumption.
- **Intention-to-treat effect (ITT)** The effect of $T$ (treatment assignment) on $Y$. 
- **Local average treatment effect (LATE)**  The effect of $D$ (taking
  treatment) on $Y$ for compliers.  Also known as the complier average causal
  effect (CACE). Under the exclusion restriction and monotonicity, the LATE is
  equal to ITT divided by the proportion of your sample who are compliers.
- **Downstream experiment** An encouragement design study that takes advantage
  of the randomization of $T$ by a previous study.  The outcome from that
  previous study is the $D$ in the downstream experiment.
