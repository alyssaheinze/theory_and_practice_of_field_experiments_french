\cleardoublepage 

# (APPENDIX) Appendix {-}

# Glossaire des termes{.tabset}

Ci-dessous voici les termes principaux, fréquemment utilisés dans le livre et plus généralement quand on parle d'expériences de terrain aléatoires.

## Concepts clés

Voir le module sur [l'inférence causale](causal-inference.html), [les estimandes et estimateurs](estimands-and-estimators.html).

- **Résultat potentiel $Y_i(T)$** Le résultat $Y$ que l'unité $i$ *aurait* sous la condition de traitement $T$. Ceux-ci sont considérés comme des quantités fixes pour un moment précis.
  $T$ peut être 0 pour le contrôle ou 1 pour le traitement s'il n'y a qu'un seul type de traitement. Voir le module sur [l'inférence causale](causal-inference.html).

- **Effet du traitement $\tau_i$ pour l'unité $i$** Le contraste entre les résultats potentiels sous les deux conditions de traitement pour l'unité $i$.
  L'effet du traitement est généralement défini comme la différence entre les résultats potentiels sous traitement et sous contrôle, $Y_i(1)-Y_i(0)$.
  Voir le module sur [l'inférence causale](causal-inference.html).

- **Problème fondamental de l'inférence causale** dans le cadre contrefactuel. On ne peut pas observer à la fois $Y_i(1)$ et $Y_i(0)$ pour une unité donnée, donc on ne peut pas obtenir $\tau_i$ directement.
  Voir le module sur [l'inférence causale](causal-inference.html).

- **Estimande** Ce que vous visez à estimer. Un exemple d'un estimande est l'effet moyen du traitement.
  Dans l'inférence causale contrefactuelle, l'effet moyen du traitement est fonction des résultats potentiels, et non des résultats observés.
  Voir le module sur les [estimandes et estimateurs](estimands-and-estimators.html).

- **Estimateur** Comment on devine la valeur de l'estimande à partir des données dont on dispose (les données observées).
  Un exemple d'estimateur est la différence des moyennes. Voir le module sur les [estimandes et estimateurs](estimands-and-estimators.html).

- **Effet moyen du traitement (Average treatment effect, ATE)** La moyenne de l'effet du traitement pour tous les individus de votre groupe de sujets.
  C'est un type d'**estimande**. Si on définit $\tau_i$ comme étant $Y_i(1)-Y_i(0)$, alors l'effet moyen du traitement est $\overline{Y_i(1)-Y_i(0)}$, ce qui équivaut aussi à $\overline{{Y}_i(1)}-\overline{{Y}_i(0)}$.
  Notez qu'on n'utilise pas le style de notation $E[Y_i (1)]$ ici parce que $E[]$ signifie "moyenne sur des opérations répétées," quand $\overline{Y}$ signifie "moyenne sur un ensemble d'observations".
  Voir le module sur [l'inférence causale](causal-inference.html) et le module sur les [estimandes et estimateurs](estimands-and-estimators.html).

- **Échantillonnage aléatoire** Sélection de sujets dans une population avec des probabilités connues strictement comprises entre 0 et 1.

- **Une experience avec $k$ bras de traitement** Une experience qui comprend $k$ conditions de traitement
  (y compris le contrôle). Voir le module sur [la randomisation](randomization.html).

- **Assignation aléatoire** Assignation des sujets à des conditions expérimentales avec des probabilités connues strictement comprises entre 0 et 1.
  Cela équivaut à un échantillonnage aléatoire sans remise à partir des résultats potentiels.
  Il existe plusieurs stratégies d'assignation aléatoire : simple, complète, par grappe (cluster), par bloc, ou une combinaison de blocs et grappes.
  Voir le module sur [la randomisation](randomization.html).

- **Validité externe** Les résultats de votre étude vous renseignent sur des contextes en dehors de votre échantillon --- dans d'autres endroits ou pour d'autres interventions.

## Inférence statistique

Voir les modules sur [les tests d'hypothèses](hypothesis-testing.html) et [la puissance statistique](statistical-power-and-design-diagnosands.html).

- **Hypothèse** Une affirmation simple, claire et falsifiable sur le monde.
  Dans l'inférence causale contrefactuelle, une hypothèse est une déclaration sur une relation pour les résultats potentiels,
  comme $H_0: Y_i(T_i=0) = Y_i(T_i=1) + \tau_i$ pour l'hypothèse que le résultat potentiel sous traitement est le résultat potentiel sous contrôle plus un certain effet pour chaque unité $i$.
  Voir le module sur [les tests d'hypothèses](hypothesis-testing.html).

- **Hypothèse nulle**  Une conjecture sur le monde que vous pouvez rejeter après avoir vu les données.
  Voir le module sur [les tests d'hypothèses](hypothesis-testing.html).

- **Hypothèse nulle stricte d'absence d'effet** L'hypothèse nulle selon laquelle il n'y a aucun effet du traitement pour aucun sujet.
  Cela signifie $Y_i(1)=Y_i(0)$ pour tout $i$. On pourrait écrire ceci comme $H_0: Y_i(T_i=0) = Y_i(T_i=1)$.
  Voir le module sur [les tests d'hypothèses](hypothesis-testing.html).

- **$p$-valeur** La probabilité de voir une statistique de test aussi grande (en valeur absolue) ou plus grande que la statistique de test calculée à partir des données observées.
  Voir le module sur [les tests d'hypothèses](hypothesis-testing.html).

- **Test unilatéral ou bilatéral** Lorsque vous vous attendez fortement à ce que l'effet soit positif ou négatif, vous pouvez effectuer un test unilatéral.
   Lorsque vous n'avez pas d'attente, effectuez un test bilatéral. Un test unilatéral a plus de puissance qu'un test bilatéral pour la même expérience.
   Voir le module sur [les tests d'hypothèses](hypothesis-testing.html).

- **Écart type** Racine carrée de l'écart quadratique moyen par rapport à la moyenne d'une variable. C'est une mesure de la dispersion d'une statistique.
  $SD_x=\sqrt{\frac{1}{n}\sum_{i=1}^n(x_i-\bar{x})^2}$

- **Taux de faux positifs/Erreur de type I d'un test** Un test d'hypothèse qui fonctionne bien rejette une hypothèse concernant un véritable effet causal pas plus de $\alpha$ % du temps.
  Le taux de faux positifs est le taux pour lequel le test met en doute une hypothèse qui est en réalité vraie.
  C'est le taux pour lequel le test incitera l'analyste à dire "statistiquement significatif" alors qu'en fait, il n'y a pas de relation causale.
  Voir le module sur [les tests d'hypothèses](hypothesis-testing.html).

- **Distribution d'échantillonnage** La distribution des estimations (par exemple, les estimations de l'ATE) pour toutes les assignations de traitement possibles.
  Pour l'inférence statistique basée sur le design des expériences randomisées, la distribution des estimations d'un estimateur est générée à partir d'une randomisation.
  Beaucoup appellent cela une "distribution d'échantillonnage" parce que les manuels utilisent souvent l'idée d'échantillons répétés d'une population plutôt que de randomisations répétées pour décrire ce type de variation.

- **Erreur type** L'écart type de la distribution d'échantillonnage. Une erreur type plus élevée signifie que nos estimations sont plus sensibles aux variations d'échantillonnage.
  Voir le module sur les [estimandes et estimateurs](estimands-and-estimateurs.html).

- **Couverture d'un intervalle de confiance** Un intervalle de confiance qui fonctionne bien contient le véritable effet causal $100 ( 1 - \alpha)$ % du temps.
  Un intervalle de confiance a une *couverture incorrecte* lorsqu'il exclut le vrai paramètre moins de $100 (1 - \alpha)$ % du temps.
  Par exemple, un intervalle de confiance à 95 % est censé exclure le vrai paramètre seulement moins de 5 % du temps.

- **Puissance statistique d'un test** Probabilité qu'un test d'effet causal détectera un effet de traitement statistiquement significatif si l'effet existe.
  Voir le module sur la [puissance statistique](statistical-power-and-design-diagnosands.html).
  Cela dépend :
    - du nombre d'observations dans chaque bras de l'expérience
    - de la taille de l'effet (généralement mesuré en unités standardisées)
    - du bruit sur la variable de résultat
    - le niveau de signification ($\alpha$, par convention)
    - d'autres facteurs, y compris la proportion de vos unités qui sont assignées à différentes conditions de traitement.

- **Corrélation intra-cluster** Dans quelle mesure les résultats potentiels des unités sont corrélés au sein des clusters par rapport à l'ensemble des clusters. Une corrélation intra-cluster plus élevée nuit à la puissance.

- **Non biaisé** Un estimateur est sans biais si vous *attendez* qu'il renvoie le bon résultat. Cela signifie que si vous deviez exécuter l'expérience plusieurs fois,
  l'estimation peut parfois être trop élevée ou trop faible, mais elle sera correcte en moyenne. Voir le module sur les [estimandes et estimateurs](estimands-and-estimateurs.html).

- **Biais** Le biais est la différence entre la valeur moyenne de l'estimateur sur l'ensemble de sa distribution d'échantillonnage et la valeur fixe unique de l'estimande.
  Voir le module sur les [estimandes et estimateurs](estimands-and-estimateurs.html).

- **Cohérence d'un estimateur** Un estimateur qui produit des réponses qui se rapprochent de plus en plus de la vraie valeur de l'estimande à mesure que la taille de l'échantillon augmente est un *estimateur cohérent* de cette estimande. Un estimateur cohérent peut être sans biais ou non.
  Voir le module sur les [estimandes et estimateurs](estimands-and-estimateurs.html).

- **Précision/efficacité d'un estimateur** La variation ou la largeur de la distribution d'échantillonnage d'un estimateur. Voir le module sur les [estimandes et estimateurs](estimands-and-estimateurs.html).

## Stratégies de randomisation

Voir le module sur [la randomisation](randomization.html).

- **Simple** Un tirage au sort indépendant pour chaque unité. Vous n'êtes pas assuré que votre expérience aura un nombre spécifique d'unités traitées.

- **Complète** Assigner $m$ sur $N$ unités au traitement. Vous savez combien d'unités seront traitées dans votre expérience et chaque unité a une probabilité de $m/N$ d'être traitée. Le nombre de façons dont le traitement peut être assigné (i.e. nombre de permutations d'assignation de traitement) est $\frac{N!}{m!(N-m)!}$.

- **Bloc** Divisez d'abord l'échantillon en blocs, puis randomisez séparément dans chaque bloc. Un bloc est un ensemble d'unités au sein duquel vous effectuez une assignation aléatoire.

- **Grappe (Cluster)** Les grappes d'unités sont assignés de manière aléatoire à une condition de traitement. Un cluster est un ensemble d'unités qui sera toujours assigné au même statut de traitement.

- **Combinaison par grappe et par bloc** Premièrement formez les blocs (de grappe). Ensuite, dans chaque bloc, assignez de manière aléatoire les grappes à une condition de traitement en utilisant une randomisation complète.

## Designs factoriels

Voir le module sur [la randomisation](randomization.html).

- **Design factoriel** Un design avec plus d'un traitement, chaque traitement étant assigné indépendamment. Le design factoriel le plus simple est un 2 par 2.

- **Effet marginal conditionnel** L'effet du traitement, conditionnel au maintien de l'autre pour une valeur fixe.
  Par exemple: $Y_i(T_1=1|T_2=0)-Y_i(T_1=0|T_2=0)$ est l'effet marginal de $T_1$ conditionnel à $T_2=0$.

- **Effet marginal moyen** Effet principal de chaque traitement dans un design factoriel.
  C'est la moyenne des effets marginaux conditionnels pour toutes les conditions de l'autre traitement, pondérée par la proportion de l'échantillon qui a été assignée à chaque condition.

- **Effet d'interaction** Dans un design factoriel, nous pouvons également estimer les effets d'interaction.
    - Pas d'effet d'interaction : un traitement n'amplifie ni ne diminue l'effet de l'autre traitement.
    - Effet d'interaction multiplicatif : l'effet d'un traitement dépend de la condition d'assignation de l'unité à un autre traitment.
      Cela signifie qu'un traitement amplifie ou réduit l'effet de l'autre. L'effet de deux traitements ensemble n'est *pas* la somme de l'effet de chaque traitement.

## Menaces

Voir le module sur les [menaces](threats-to-internal-validity-of-randomized-experiments.html).

- **Effet Hawthorne** lorsqu'un sujet réagit différemment quand il est observé.

- **Effet de débordement** lorsqu'un sujet répond au statut de traitement d'un autre sujet.
   Exemple : ma santé dépend du statut de vaccination de mon voisin, ainsi que de mon statut.

- **Attrition** Lorsque les résultats pour certains sujets ne sont pas mesurés.
   Cela peut être causé, par exemple, par des personnes qui migrent, refusent de répondre aux enquêtes finales ou meurent.
   Ceci est particulièrement problématique pour l'inférence lorsque l'attrition est corrélée avec le statut du traitement.

- **Conformité** Le statut de traitement d'une unité correspond à la condition de traitement qui lui a été assignée.
   Exemple de non-conformité : une unité assignée au traitement ne le prend pas.
   Exemple de conformité : une unité assignée au contrôle ne prend pas de traitement.

- **Types de conformité** Il existe quatre types d'unités en termes de conformité :
     - **Conformistes** Unités qui prendraient un traitement si elles étaient assignées au traitement et qui ne seraient pas traitées si elles étaient assignées au contrôle.
     - **Toujours preneurs** Unités qui prendraient un traitement si elles étaient assignées au traitement et si elles étaient assignées au contrôle.
     - **Jamais preneurs** Unités qui ne seraient pas traitées si elles étaient assignées au traitement et si elles étaient assignées au contrôle.
     - **Non-conformistes** Unités qui ne seraient pas traitées si elles étaient assignées au traitement et qui prendraient un traitement si elles étaient assignées au contrôle.

- **Non-conformité unilatérale** L'expérience n'a que des sujets "conformistes" et *soit* des "toujours preneurs" ou des "jamais preneurs".
  Habituellement, nous pensons à la non-conformité unilatérale comme n'ayant que des sujets "jamais-preneurs" et "conformistes", ce qui signifie que l'effet moyen local du traitement est l'effet du traitement sur le traité.

- **Non-conformité bilatérale** L'expérience peut avoir les quatre groupes latents.

- **Design incitatif** Une expérience qui randomise $T$ (assignation de traitement), et nous mesurons $D$ (si l'unité prend le traitement) et $Y$ (le résultat).
  On peut estimer l'effet d'intention de traiter (intent to treat effect, ITT), l'effet moyen local du traitement (Local average treatment effect, LATE) aussi connu sous le nom d'effet causal moyen pour ceux qui se conforment au traitement (complier average causal effect, CACE). Cela nécessite trois hypothèses.
     - **Monotonicité** Hypothèse qu'il n'y a pas de sujets non-conformistes ou bien pas de conformistes.
       Habituellement, nous supposons qu'il n'y a pas de non-conformistes, ce qui signifie que l'effet de l'assignation sur la prise du traitement est soit positif, soit nul mais pas négatif.
     - **Première étape** Hypothèse qu'il y a un effet de $T$ sur $D$.
     - **Restriction d'exclusion** Hypothèse selon laquelle $T$ affecte $Y$ uniquement à travers $D$. C'est généralement l'hypothèse la plus problématique.

- **Effet d'intention de traiter (intent to treat effect, ITT)** L'effet de $T$ (assignation de traitement) sur $Y$.

- **Effet moyen local du traitement (Local average treatment effect, LATE)** L'effet de $D$ (prise de traitement) sur $Y$ pour les conformistes.
  Également connu sous le nom d'effet causal moyen pour ceux qui se conforment au traitement (complier average causal effect, CACE).
  Si l'hypothèse de monotonie et la restriction d'exclusion sont remplies, le LATE est égal à l'ITT divisé par la proportion conformiste de votre échantillon.

- **Expérience aval** Une étude de design incitatif qui profite de la randomisation de $T$ d'une étude précédente.
  Le résultat de cette étude précédente est le $D$ dans l'expérience aval.
