[["index.html", "Module 1 Introduction 1.1 Comment utiliser le livre 1.2 Nous apprécions vos retours! 1.3 Remerciements", " La théorie et la pratique des expériences de terrain : Une introduction des EGAP Learning Days Jake Bowers,1 Maarten Voors,2 et Nahomi Ichino3 September 28, 2021 Module 1 Introduction Durant la dernière décennie, Evidence in Governance and Politics (EGAP) a organisé une série de workshops, les Learning Days, dans le but de renforcer les compétences en recherche expérimentale en sciences sociales parmi les directeurs de recherche  cheurcheurs et praticiens  en Afrique et Amérique Latine. En partageant entre participants, méthodes pratiques et méthodes statistiques pour mener des expériences de terrain aléatoires, les Learning Days visent à créer et entretenir des réseaux de chercheurs dans le monde et à faciliter des liens solides et productifs entre ces chercheurs et les membres de EGAP. Les Learning Days sont une combinaison dateliers de design, de présentations de travaux de recherche, dutilisation de logiciel statistique et de conférences thématiques par un petit groupe dinstructeurs, principalement des professeurs et des doctorants du réseau de EGAP. Les workshops abordent les méthodes de design et danalyse pour des expériences de terrain aléatoires plutôt que des expériences aléatoires en laboratoire ou des études non-aléatoires. Ce livre rassemble les matériaux développés pour les Learning Days. La version actuelle du livre est écrite principalement pour des instructeurs et des organisateurs de workshops et de cours similaires pour des directeurs de recherche  des professeurs, des cheurcheurs postdoctorals, des doctorants, des évaluateurs dONG et dagences gouvernementales, etc  qui réaliseront des études aléatoires de programmes liés aux institutions, à la gouvernance et au développement. Une grande partie des matériaux sera également utile comme rappel pour les participants des Learning Days précédents. Ce livre est une revue complète des méthodes dinférence causale pour les chercheurs qui développent un design de recherche expérimental. Ce livre est organisé en modules et comprend des sujets tels que linférence causale, la randomisation, les tests dhypothèses, les estimandes, les estimateurs, la puissance statistique, la mesure, les menaces pour la validité interne et léthique de lexpérimentation. Les modules apparaissent dans lordre jugé le plus utile. Cependant, les modules sont liés et peuvent être réorganisés afin de correspondre à vos besoins en tant quinstructeur. En annexe, il y a des matériaux préparatoires comprenant un glossaire des termes et une introduction à R et RStudio. Ce livre comprend des slides sur le contenu principal, le formulaire de design de recherche de EGAP et des références dexemples de recherche et des slides utilisées pendant les Learning Days précédents. Ces matériaux renforcent le travail de EGAP sur la méthodologie, résumé dans les guides de méthodes de EGAP. Comparé aux Learning Days précédents, nous avons ajouté plus de matériaux sur les tests dhypothèses, lestimation et la puissance statistique. De nouveaux modules sur le processus de design de recherche, la mesure et les considérations éthiques sont désormais disponibles. Les slides et les modules présentés ici contiennent trop dinformations pour être couverts en une seule semaine, la durée habituelle dun workshop Learning Days. Cependant, nous avons décidé de conserver toutes les informations, afin daider les instructeurs à adapter leurs cours à leurs publics réspectifs. 1.1 Comment utiliser le livre Pour profiter au maximum de ce livre, veuillez installer R et RStudio sur votre machine. En fait, les slides supposent que vous utilisiez Rmarkdown pour les adapter à vos besoins. Pour commencer avec R, voir le module Introduction à R et RStudio. Vous pouvez copier ce livre ou des parties de celui-ci (des slides, etc) soit en utilisant le bouton de téléchargement (Download) sur la première page de http://github.com/egap/theory_and_practice_of_field_experiments_french, soit directement sur github en forkant ce repertoire. Tant que vous citiez EGAP, vous pouvez utiliser ces matériaux. Veuillez consulter la licence Creative Commons Attribution-ShareAlike 4.0 International pour les termes exacts. 1.2 Nous apprécions vos retours! Si vous avez des questions, des retours, ou si vous avez organisé votre propre événement, contactez-nous! Il suffit de créer une issue sur Github ou faire des commentaires en utilisant hypothes.is dans votre navigateur et de nous le faire savoir par e-mail, admin@egap.org. Nous parcourons régulièrement vos commentaires. 1.3 Remerciements Les matériaux dans ce livre ont été développés au cours des derniers Learning Days par divers instructeurs. Ceux-ci incluent (par ordre alphabétique) Jake Bowers, Jasper Cooper, Ana De la O, Lindsay Dolan, Natalia Garbiras Díaz, Macartan Humphreys, Nahomi Ichino, Salif Jaiteh, Gareth Nellis, Dan Nielson, Rafael Piñeiro, Fernando Rosenblatt, Tara Slough, Peter van der Windt et Maarten Voors. Nous remercions Natalia Garbiras Díaz, Macartan Humphreys, Anghella Brigeth Rosero Rodriguez, et Tara Slough en particulier pour leurs commentaires sur une première version du livre. Chez EGAP, Matt Lisiecki, Ingrid Lee, Goldie Negelev, Max Mendez-Back et dautres ont apporté un soutien formidable. Les Learning Days ont été généreusement financés par la Fondation Hewlett et soutenus par des institutions du monde entier, notamment lAfrican School of Economics (Bénin), lUniversité de Diego Portales (Chili), lUniversité de los Andes (Colombie), le Ghana Center for Democratic Development (Ghana) , Mercy Corps (Guatemala), Invest in Knowledge (Malawi), NYU Abu Dhabi (EAU), et lUniversité catholique de lUruguay (Uruguay). Lordre des noms dauteurs est généré de manière aléatoire. https://jakebowers.org https://sites.google.com/site/maartenvoors/ https://nahomi.github.io/ "],["processus-de-design-de-recherche.html", "Module 2 Processus de design de recherche 2.1 Contenu 2.2 Slides 2.3 Formulaire de design et pré-enregistrement 2.4 Ressources", " Module 2 Processus de design de recherche Ce livre vise à vous aider à comprendre et à concevoir des expériences de terrain aléatoires. Avant dentrer dans le détail du design de recherche, nous avons besoin dune bonne question de recherche - une question qui fera progresser les connaissances ou aidera à prendre une décision politique, ou les deux. Il ny a pas de recette simple pour trouver ou développer une bonne question scientifique ou politique, mais nos théories sont importantes pour articuler les bonnes questions qui sous-tendent une recherche percutante. Après avoir formulé notre question, nous développons le meilleur design possible dans les limites de nos moyens, en utilisant notre connaissance de linférence causale et des statistiques des modules qui suivent. Ce module présente le formulaire de design de recherche EGAP, une checklist pour vous guider à travers les nombreuses étapes du processus de recherche. Les Learning Days sont organisés autour du formulaire de design de recherche. Nous vous incitons à utilser le logiciel DeclareDesign pour explorer les implications des différents choix que nous pourrions faire pour nos designs de recherche. Enfin, ce module aborde les plans de pré-analyse et de pré-enregistrement. Lorsque nous planifions nos analyses et rendons ces plans publics, nous améliorons nos chances de convaincre les autres avec nos résultats. 2.1 Contenu Une bonne question de recherche fait progresser la science et/ou est une question dont la réponse éclairera une décision politique. Certains designs de recherche sont mieux pour répondre à certaines questions. Nous voulons choisir le design qui répond le mieux à nos questions clés compte tenu des contraintes et de nos moyens. Les questions que nous posons découlent  souvent implicitement  de nos valeurs et de notre compréhension du fonctionnement du monde. Ces théories rendent nos questions pertinentes. Et les expériences que nous réalisons nous renseignent sur la théorie. Cependant, nous espérons que les preuves et les données issues de ces designs de recherche amélioreront notre compréhension. Composants de base dun design de recherche Présentation des composants de base de formulaire de design de recherche EGAP. Introduire le package pour le design de recherche, DeclareDesign. Lévolution des sciences sociales vers lexamen des designs, au lieu de lexamination des résultats. Le pré-enregistrement  ce que cest, et pourquoi et comment nous devons le faire. 2.2 Slides Vous trouverez ci-dessous des slides avec le contenu de base de notre conférence sur le recherche de design. Vous pouvez les utiliser directement ou les copier localement avant de les éditer. Code source en R Markdown Version PDF Version HTML Vous pouvez aussi lire les slides des précédents EGAP Learning Days: Présentation de DeclareDesign aux EGAP Learning Days à lUniversité catholique dUruguay, Montevideo, mars 2018 Présentation de DeclareDesign aux EGAP Learning Days à Salima, Malawi, février 2017 Présentation de DeclareDesign aux EGAP Learning Days à lUniversité Diego Portales à Santiago, Chili, mai 2016 Vous pouvez également voir les slides des Design Talks lors des précédents EGAP Learning Days, où les présentateurs se concentrent sur les problèmatiques relatives dans le design de la recherche, au lieu des résultats: Design Talk aux EGAP Learning Days à lAfrican School of Economics, Benin, mars 2018 Design Talk 1 aux EGAP Learning Days à lUniversité catholique dUruguay, Montevideo, mars 2018 Design Talk 2 aux EGAP Learning Days à lUniversité catholique dUruguay, Montevideo, mars 2018 Design Talk 3 aux EGAP Learning Days à lUniversité catholique dUruguay, Montevideo, mars 2018 Design Talk 1 aux EGAP Learning Days à lUniversité Diego Portales à Santiago, Chili, mai 2016 Design Talk 2 aux EGAP Learning Days à lUniversité Diego Portales à Santiago, Chili, mai 2016 Design Talk 3 aux EGAP Learning Days à lUniversité Diego Portales à Santiago, Chili, mai 2016 Design Talk from EGAP Learning Days à Guatemala City, Guatemala, août 2017 2.3 Formulaire de design et pré-enregistrement Formulaire de design de recherche EGAP. Une checklist que nous avons créée pour les Learning Days pour vous guider à travers les étapes du processus de recherche. Version Docx Version PDF Version HTML Liens vers les répertoires pour pré-enregistrement/plans de pré-analyse: Le registre EGAP, hébergé par OSF (https://egap.org/registry/) Le registre AEA RCT (https://www.socialscienceregistry.org/) OSF (https://osf.io/registries) Exemples dautres pré-enregistrements/plans de pré-analyse: SMS au Mozambique du gouvernement fédéral américain Caméras portatives pour les policiers du Lab @ DC 2.4 Ressources 2.4.1 Guide des méthodes EGAP Guide des méthodes EGAP 10 choses à savoir sur les plans de pré-analyse Guide des méthodes EGAP 10 choses à savoir sur la mesure dans les expériences 2.4.2 Livres, chapitres et articles Pré-enregistrement comme outil pour renforcer lévaluation fédérale. Le livre blanc de lOffice of Evaluation Sciences du gouvernement américain. Vous pouvez également voir leurs exemples de plans de pré-analyse pour toutes leurs pages dexpériences de terrain. Garret S. Christensen, Jeremy Freese, and Edward Miguel, Transparent and Reproducible Social Science Research: How to Do Open Science (Oakland, California: University of California Press, 2019). Le livre résume les nouvelles approches de la recherche en sciences sociales sur la transparence et la reproductibilité. Alan S. Gerber and Donald P. Green, Field Experiments: Design, Analysis, and Interpretation (New York, NY: W. W. Norton &amp; Company, 2012). Le chapitre 12 comprend quelques exemples de designs de recherche expérimentale. 2.4.3 Outils DeclareDesign, un ensemble passionnant et complet doutils logiciels pour décrire, évaluer et mener des recherches empiriques. References "],["inférence-causale.html", "Module 3 Inférence causale 3.1 Contenu 3.2 Slides 3.3 Ressources", " Module 3 Inférence causale Une grande partie des sciences sociales porte sur la causalité. On peut se demander si linscription des électeurs augmente la participation politique, si la responsabilisation bottom-up peut améliorer les perspectives en matière de santé, ou si les récits personnels des migrants aident à réduire les attitudes préjudiciables à leur égard. Au cours de la dernière décennie, les sciences sociales sont devenues beaucoup plus strictes quant à la formulation des assertions de causalité, en sappuyant sur une longue histoire de travaux sur la causalité remontant aux classiques de Fisher and Rubin. On recourt davantage aux expériences ; la randomisation est devenue la norme de référence pour répondre aux questions causales. Dans ce module, nous introduisons lapproche contrefactuelle de linférence causale et comment des affirmations basées sur des assertions de causalité peuvent être interprétées. Nous présentons le modèle à résultats potentiels et la manière dont lassignation aléatoire nous aide à faire des assertions sur ce qui se serait passé en labsence de la politique publique, de laction ou du programme que nous étudions. Nous discutons des trois hypothèses de base pour linférence causale : lassignation aléatoire des sujets au traitement, la non-interférence et lexcluabilité. 3.1 Contenu Quentendons-nous par cause? Et pourquoi est-il important dêtre clair sur le sens des assertions de causalité? Une introduction aux résultats potentiels comme une façon de penser aux états contrefactuels du monde. La randomisation nous aide à comprendre les assertions causales contrefactuelles dune manière particulièrement utile. Les trois principales hypothèses de base pour linférence causale : lassignation aléatoire des sujets au traitement, la non-interférence et lexcluabilité. Comparaison des études aléatoires avec des études dobservation. La randomisation apporte une validité interne élevée, mais elle ne peut pas assurer la validité externe. Votre question causale est liée à votredesign de recherche. 3.2 Slides Vous trouverez ci-dessous des slides avec le contenu de base de notre conférence sur la causalité. Vous pouvez les utiliser directement ou les copier localement avant de les éditer. Code source en R Markdown Version PDF Version HTML Vous pouvez aussi lire les slides des précédents EGAP Learning Days: La présentation de linférence causale aux EGAP Learning Days à lAfrican School of Economics, Abomey-Calavi, juin 2019 La présentation de linférence causale aux EGAP Learning Days à lUniversité des Andes, Bogotá, avril 2019 La présentation de linférence causale aux EGAP Learning Days à lUniversité catholique dUruguay, Montevideo, mars 2018 La présentation de linférence causale aux EGAP Learning Days à Guatemala City, Guatemala, août 2017 La présentation à lintroduction sur les expériences aux EGAP Learning Days à Guatemala City, Guatemala, août 2017 La présentation de linférence causale aux EGAP Learning Days à Salima, Malawi, février 2017 La présentation de linférence causale aux EGAP Learning Days à lUniversité Diego Portales à Santiago, Chili, mai 2016 3.3 Ressources 3.3.1 Guide des méthodes EGAP Guide des méthodes EGAP 10 choses à savoir sur linférence causale Guide des méthodes EGAP 10 stratégies pour déterminer si X a causé Y Guide des méthodes EGAP 10 choses à savoir sur les mécanismes Guide des méthodes EGAP 10 choses à savoir sur la validité externe 3.3.2 Livres, chapitres et articles 3.3.2.1 Classiques Ronald A. Fisher, The Design of Experiments (Edinburgh: Oliver; Boyd, 1935). Fisher introduit lidée de la randomisation et des tests dhypothèses pour apprendre linférence causale. Donald B. Rubin, Estimating the Causal Effects of Treatments in Randomized and Nonrandomized Studies, J. Educ. Psych. 66 (1974): 688701. Rubin introduit lidée de résultats potentiels et relie les conceptualisations contrefactuelles de la causalité à linférence statistique. 3.3.2.2 Revue actuelle Henry E Brady, Causation and Explanation in Social Science, in The Oxford Handbook of Political Science, 2008, https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199286546.001.0001/oxfordhb-9780199286546-e-10. Gerber and Green, Field Experiments, Chapitre 1. Ce livre est une excellente ressource pour de nombreux sujets du design expérimental. Stephen L. Morgan and Christopher Winship, Counterfactuals and Causal Inference: Methods and Principles for Social Research (Cambridge University Press, 2007), Chapitre 1. Ce livre comprend de bons examples de raisonnement pour faire des assertions de causalité à partir de données dobservation. Rachel Glennerster and Kudzai Takavarasha, Running Randomized Evaluations: A Practical Guide (Princeton: Princeton University Press, 2013). Ceci est une excellente introduction pour mener des expériences de terrain illustrée par nombreux exemples. 3.3.3 Notes dorientation des politiques publiques EGAP Quelques exemples de questions causales : Note dorientation des politiques publiques EGAP 38 : Les campagnes déducation des électeurs à la radio sont-elles efficaces pour décourager les électeurs de voter pour des partis ou candidats qui sengagent dans lachat de voix ? Note dorientation des politiques publiques EGAP 51 : Les technologies de linformation et de communication gratuites et anonymes peuvent-elles renforcer la responsabilité locale et améliorer les prestations de services publics ? Note dorientation des politiques publiques EGAP 58 : La responsabilisation bottom-up peut-elle améliorer les perspectives en matière de santé ? Note dorientation des politiques publiques EGAP 69 : Une surveillance citoyenne bottom-up améliore-t-elle les prestations de services publics ? References "],["randomisation.html", "Module 4 Randomisation 4.1 Contenu 4.2 Slides 4.3 Ressources", " Module 4 Randomisation Le module sur linférence causale aborde le rôle important de la randomisation pour tirer des inférences valides à partir dune comparaison des groupes traités et non traités. Dans ce module, nous passons de la théorie aux cas concrets pour votre design de recherche. Nous introduisons quatre façons courantes de randomiser le traitement  simple, complète, par bloc, et en grappe (cluster)  et quand ces différents types de randomisation sont disponibles et appropriés. Nous couvrons également plusieurs designs courants, y compris les designs factoriels et les designs incitatifs. Le module fournit des conseils sur limplementation, y compris les meilleures pratiques pour vérifier lhomogénéité et assurer la reproductibilité. 4.1 Contenu Quest-ce que la randomisation? Lassignation aléatoire nest pas la même que léchantillonnage aléatoire. Quatre façons courantes de randomiser le traitement : Simple : assigner de manière aléatoire des unités au traitement (comme un tirage au sort). Complète : au sein dune liste dunités éligibles, assigner un numéro fixe pour recevoir un traitement (comme tirer dune urne). Par bloc (ou stratifié) : assigner un traitement dans des strates ou des blocs spécifiques, comme si vous meniez une expérience dans chaque bloc. En grappe (cluster) : assigner des groupes (grappes ou clusters) dobservations à la même condition de traitement. Quelques designs courants: Accès randomisé : randomiser la disponibilité du traitement. Accès differé randomisé : randomiser le timing de laccès. Factoriel : randomiser les unités en combinaisons de bras de traitement. Incitatif : randomiser linvitation à recevoir le traitement. Comment vérifier si votre randomisation a produit des groupes homogènes sur les caractéristiques observables ? En règle générale, nous effectuons des tests de randomisation, également appelés tests dhomogénéité. On peut, par exemple, utiliser le test omnibus \\(d^2\\) de xBalance dans le package RItools (car cest une inférence basée sur la randomisation) ou on peut approximer ce résultat avec un test \\(F\\). La randomisation a des limites. Nous en discutons ici et nous vous orientons vers le module sur les menaces pour en savoir plus. 4.2 Slides Vous trouverez ci-dessous des slides avec le contenu de base de notre conférence sur la randomisation. Vous pouvez les utiliser directement ou les copier localement avant de les éditer. Code source en R Markdown Version PDF Version HTML Les fichiers liés montrent comment faire de la randomisation réplicable en R. Vous pouvez également voir plus dexemples de randomisation en R sur 10 choses à savoir sur la randomisation. Vous pouvez aussi lire les slides des précédents EGAP Learning Days: La présentation des issues de design aux EGAP Learning Days à lAfrican School of Economics, Abomey-Calavi, juin 2019 (la première section passe en revue les designs de randomisation) La présentation de la randomisation aux EGAP Learning Days à lUniversité des Andes, Bogotá, avril 2019 La présentation de la randomisation aux EGAP Learning Days à lUniversité catholique dUruguay, Montevideo, mars 2018 La présentation de la randomisation aux EGAP Learning Days à Guatemala City, Guatemala, août 2017 La présentation de la randomisation aux EGAP Learning Days à Salima, Malawi, février 2017 La présentation de la randomisation aux EGAP Learning Days à lUniversité Diego Portales à Santiago, Chili, mai 2016 4.3 Ressources 4.3.1 Guide des méthodes EGAP Guide des méthodes EGAP 10 choses à savoir sur la randomisation Guide des méthodes EGAP 10 choses à savoir sur la randomisation par grappe (cluster) 4.3.2 Livres, chapitres et articles Procédures opérationnelles standard pour le laboratoire de Don Green à lUniversité de Columbia. Un ensemble complet de procédures et de règles empiriques pour mener des études expérimentales. Glennerster and Takavarasha, Running Randomized Evaluations. Chapitre 2 sur la randomisation. Gerber and Green, Field Experiments. Chapitre 2 : Inférence causale et expérimentation 4.3.3 Notes dorientation des politiques publiques EGAP Designs factoriels Note dorientation des politiques publiques EGAP 57 : Comment les médias influencent les normes sociales : la preuve au Mexique Note dorientation des politiques publiques EGAP 58 : La responsabilisation bottom-up fonctionne-t-elle ? Randomiser laccès Note dorientation des politiques publiques EGAP 24 : Réduire laccaparation par les élites dans les îles Salomon Accès differé randomisé Note dorientation des politiques publiques EGAP 35 : Réduire la récidive parmi les détenus libérés Note dorientation des politiques publiques EGAP 60 : Réduire le soutien des jeunes à la violence grâce à la formation et aux transferts de cash en Afghanistan Randomisation en grappe (cluster) Note dorientation des politiques publiques EGAP 22 : Pousser au vote Randomisation en grappe bloquée Note dorientation des politiques publiques EGAP 54 : Révélations de malversations des politicens en place Note dorientation des politiques publiques EGAP 56 : Signaler la corruption 4.3.4 Outils RItools, un ensemble doutils pour linférence basée sur la randomisation, y compris le test dhomogénéité. 4.3.5 Courtes vidéos explicatives Randomisation vs. échantillonnage aléatoire Randomisation en grappes vs en blocs References "],["tests-dhypothèses.html", "Module 5 Tests dhypothèses 5.1 Contenu 5.2 Slides 5.3 Ressources", " Module 5 Tests dhypothèses Ce nest pas possible dobserver directement des effets causaux à cause du problème fondamental de linférence causale (module de linférence causale). Comment pouvons-nous en savoir plus sur ces effets causaux non observés en utilisant ce que nous observons? Dans une expérience aléatoire, nous pouvons évaluer des suppositions ou des hypothèses sur les effets causaux non observés. Pour ce faire, nous comparons ce que nous observons dans une expérience à ce que nous observerions si nous pouvions répéter la manipulation expérimentale et que la supposition ou lhypothèse était vraie. Dans ce module, nous présentons les tests dhypothèses, leur lien avec linférence causale, les \\(p\\)-valeurs et ce quil faut faire lorsque nous avons plusieurs hypothèses à tester. 5.1 Contenu Quest-ce quune bonne hypothèse ? La relation entre les tests dhypothèses et linférence causale. Tests dhypothèses. Lhypothèse nulle. Estimateurs versus statistiques de test. Dans une expérience, une distribution de référence pour un test dhypothèse provient du design expérimental et de la randomisation. Les \\(p\\)-valeurs et comment interpréter les résultats des tests dhypothèses. Un bon test dhypothèse doit (1) rarement mettre en doute la vérité (cest-à-dire avoir un taux de faux positifs contrôlé et faible) et (2) distinguer facilement le signal du bruit (cest-à-dire mettre souvent en doute les contrevérités ; avoir une puissance statistique élevée) . Comment saurons-nous si notre test dhypothèse performe bien? (Analyse de puissance a son propre module). Taux de faux positifs. Couverture correcte de lintervalle de confiance. Évaluer le taux de faux positifs dun test dhypothèse pour un design donné et un choix de statistique de test; cas dun essai aléatoire par grappe/cluster et lerreur standard robuste pour cluster. Soyez prudent lorsque vous testez de nombreuses hypothèses, par exemple quand vous avez plus de deux bras de traitement ou que vous évaluez les effets dun traitement sur plusieurs résultats. Nous devons veiller à ajuster les \\(p\\)-valeurs ou les intervalles de confiance pour refléter le nombre de tests ou dintervalles produits. 5.2 Slides Vous trouverez ci-dessous des slides avec le contenu de base de notre conférence sur les tests dhypothèses. Vous pouvez les utiliser directement ou les copier localement avant de les éditer. Code source en R Markdown Version PDF Version HTML Vous pouvez aussi lire les slides des précédents EGAP Learning Days: La présentation des tests dhypothèses aux EGAP Learning Days à lAfrican School of Economics, Abomey-Calavi, juin 2019 La présentation des tests dhypothèses aux EGAP Learning Days à lUniversité des Andes, Bogotá, avril 2019 La présentation des tests dhypothèses aux EGAP Learning Days à lUniversité catholique dUruguay, Montevideo, mars 2018 La présentation des tests dhypothèses aux EGAP Learning Days à Guatemala City, Guatemala, août 2017 La présentation des tests dhypothèses aux EGAP Learning Days à Salima, Malawi, février 2017 La présentation des tests dhypothèses aux EGAP Learning Days à lUniversité Diego Portales à Santiago, Chili, mai 2016 5.3 Ressources 5.3.1 Guide des méthodes EGAP Guide des méthodes EGAP 10 choses à savoir sur les tests dhypothèse Guide des méthodes EGAP 10 choses à savoir sur les comparaisons multiples 5.3.2 Livres, chapitres et articles Gerber and Green, Field Experiments. Chapitre 3 : Distributions déchantillonnage, inférence statistique et test dhypothèse. Paul R. Rosenbaum, Design of observational studies, Springer Series in Statistics (2010). Chapitre 2 : Inférence causale dans les expériences aléatoires. Paul R. Rosenbaum, Observation and Experiment: An Introduction to Causal Inference (Harvard University Press, 2017). Partie I : Expériences aléatoires. References "],["estimandes-et-estimateurs.html", "Module 6 Estimandes et estimateurs 6.1 Contenu 6.2 Slides 6.3 Ressources", " Module 6 Estimandes et estimateurs Les expériences aléatoires génèrent de bonnes suppositions sur le résultat moyen sous traitement et le résultat moyen sous contrôle. Cela nous permet davoir des estimateurs sans biais des effets moyens du traitement. Nous pouvons également utiliser la randomisation pour décrire comment les estimations générées par un estimateur peuvent varier dune expérience à lautre avec des erreurs standards et des intervalles de confiance. Dans ce module, nous introduisons plusieurs types destimandes. Le choix de lestimande est une décision scientifique et politique  sur quelle quantité aimerions-nous en savoir plus ? De plus, nous voulons sélectionner un estimateur approprié pour cette estimande dans le cadre du design de recherche. Nous discutons de la façon dont les estimateurs sont appliqués aux données pour générer un estimande et comment caractériser sa variabilité. 6.1 Contenu Un effet causal, \\(\\tau_i\\), est une comparaison des résultats potentiels non observés pour chaque unité \\(i\\). Par exemple, cela peut être une différence ou un ratio de résultats potentiels non observés. Pour en savoir plus sur \\(\\tau_{i}\\), on peut traiter \\(\\tau_{i}\\) comme estimande ou quantité cible à estimer (ce module) ou comme quantité cible sur laquelle émettre une hypothèse (module de test dhypothèse). Beaucoup de gens se concentrent sur leffet moyen du traitement (ATE), \\(\\bar{\\tau}=\\sum_{i=1}^n \\tau_{i}\\), en partie parce quil permet destimer facilement. Un estimateur est une recette pour calculer une supposition sur la valeur dun estimande. Par exemple, la différence entre la moyenne des résultats observés pour \\(m\\) unités traitées et la moyenne des résultats observés pour \\(N-m\\) unités non traitées est un estimateur de \\(\\bar{\\tau}\\). Différentes randomisations produiront différentes valeurs du même estimateur ciblant le même estimande. Une erreur standard résume cette variabilité dans un estimateur. Un intervalle de confiance de \\(100(1-\\alpha)\\)% est un ensemble dhypothèses qui ne peuvent être rejetées au niveau \\(\\alpha\\). Nous avons tendance à rapporter des intervalles de confiance contenant des hypothèses sur les valeurs de notre estimande et à utiliser notre estimateur comme statistique de test. Les estimateurs devraient (1) éviter les erreurs systématiques dans leur estimation de lestimande (être sans biais) ; (2) varient peu dans leurs suppositions dune expérience à lautre (être précis ou efficace) ; et peut-être idéalement (3) converger vers lestimande quand ils utilisent de plus en plus dinformations (être cohérent). Analyser en randomisant dans le contexte de lestimation signifie que (1) nos erreurs standards devraient mesurer la variabilité de la randomisation et (2) nos estimateurs devraient cibler des estimandes définis en termes de résultats potentiels. Nous ne contrôlons pas les covariables lorsque nous analysons les données dexpériences aléatoires. Pourtant les covariables peuvent rendre notre estimation plus précise. Cest ce quon appelle lajustement de covariable. Lajustement de covariable dans les expériences aléatoires diffère du contrôle des variables dans les études dobservation. Une intervention politique (comme une lettre qui encourage lexercice) peut avoir lintention de changer un comportement par une dose active (exercice réel). Nous pouvons apprendre leffet causal de lintention en envoyent les lettres de façon aléatoire. Cest ce quon appele leffet dintention de traiter (intent to treat effect, ITT). Nous pouvons apprendre sur leffet causal de lexercice réel en utilisant lattribution aléatoire de lettres comme instrument la dose active (lexercice lui-même) afin dapprendre davantage sur leffet causal de lexercice chez ceux qui changeraient leur comportement après avoir reçu la lettre. Cette version de leffet causal moyen est souvent connue sous le nom deffet moyen local du traitement. 6.2 Slides Vous trouverez ci-dessous des slides avec le contenu de base pour cette section. Code source en R Markdown Version PDF Version HTML Vous pouvez aussi lire les slides des précédents EGAP Learning Days: La présentation de lestimation aux EGAP Learning Days à lAfrican School of Economics, Abomey-Calavi, juin 2019 La présentation de lestimation aux EGAP Learning Days à lUniversité des Andes, Bogotá, avril 2019 La présentation de lestimation aux EGAP Learning Days à lUniversité catholique dUruguay, Montevideo, mars 2018 La présentation de lestimation aux EGAP Learning Days à lUniversité Diego Portales à Santiago, Chili, mai 2016 Vous pouvez également voir les problèmes destimation de leffet de la dose active dun traitement dans ces slides (ainsi que les problèmes causés par les données manquantes sur les résultats pour lestimation de leffet causal moyen) : La présentation des problèmes de design aux EGAP Learning Days à lAfrican School of Economics, Abomey-Calavi, juin 2019 (first section reviews randomization designs) La présentation des effets de débordement et de lattrition aux EGAP Learning Days à Guatemala City, Guatemala, août 2017 La présentation des menaces aux EGAP Learning Days à Guatemala City, Guatemala, août 2017 La présentation des complications aux EGAP Learning Days à Salima, Malawi, février 2017 La présentation des menaces aux EGAP Learning Days à lUniversité Diego Portales à Santiago, Chili, mai 2016 (la section du milieu examine lITT et la non-conformité) 6.3 Ressources 6.3.1 Guide des méthodes EGAP Guide des méthodes EGAP Les 10 effets de traitement que vous devez connaître Guide des méthodes EGAP 10 choses à savoir sur lajustement de covariante Guide des méthodes EGAP 10 choses à savoir sur les données manquantes Guide des méthodes EGAP 10 choses à savoir sur leffet moyen local du traitement Guide des méthodes EGAP 10 choses à savoir sur les effets de débordement 6.3.2 Livres, chapitres et articles Gerber and Green, Field Experiments. Chapitre 2.7 sur lexcluabilité et la non-interférence, Chapitre 3, Chapitre 5 sur la non-conformité unilatérale, Chapitre 6 sur la non-conformité bilatérale, Chapitre 7 sur lattrition, Chapitre 8 sur linterférence entre les unités expérimentales. Jake Bowers and Thomas Leavitt, Causality &amp; Design-Based Inference, in The SAGE Handbook of Research Methods in Political Science and International Relations, ed. Luigi Curini and Robert Franzese (Sage Publications Ltd, 2020). 6.3.3 Outils DeclareDesign Le package estimatr en R References "],["puissance-statistique-et-diagnosands-de-design.html", "Module 7 Puissance statistique et diagnosands de design 7.1 Contenu 7.2 Slides 7.3 Ressources", " Module 7 Puissance statistique et diagnosands de design Avant de commencer une étude, nous aimerions savoir si notre design a la puissance statistique de détecter un effet sil existe. Il est difficile dapprendre dune étude qui na pas une puissance statistique suffisante. Sans une puissance statistique suffisante, nous ne savons pas si un résultat nul signifie quil ny a en fait pas eu deffet, ou que nous navons pas réussi à détecter un effet non nul qui existe. Une analyse de puissance peut vous aider à améliorer votre design et à mieux répartir vos ressources. Cela peut même vous aider à décider de ne pas mener létude. Dans ce module, nous introduisons la puissance statistique, approches de base pour calculer la puissance par des calculs analytiques et par la simulation, et comment les caractéristiques de design telles que les blocs, lajustement des covariables et les grappes (clusters) ont un impact sur la puissance statistique. 7.1 Contenu La puissance statistique est la capacité dune étude à détecter un effet sil existe. Lanalyse de puissance seffectue avant la réalisation dune étude. Cela aide à déterminer léchantillon dont on a besoin ou les effets que lon peut détecter. Cest une étape essentielle dans le design de recherche et aide à communiquer sur son design. Méthodes courantes de calcul de puissance : Calculs de puissance analytique (en utilisant une formule) Simulations (par exemple, en utilisant DeclareDesign) Lajustement des covariables et les blocs peuvent augmenter la puissance statistique. Pour les designs par grappe il faut tenir compte de la corrélation intra-grappe (la variance intra-grappe par rapport à la variance globale). La puissance statistique est étroitement liée au [design de létude] (the-research-design-process.html), aux tests dhypothèses et à lestimation. 7.2 Slides Vous trouverez ci-dessous des slides avec le contenu de base de notre conférence sur la puissance statistique. Vous pouvez les utiliser directement ou les copier localement avant de les éditer. Code source en R Markdown Version PDF Version HTML Vous pouvez aussi lire les slides des précédents EGAP Learning Days: La présentation de la puissance statistique des EGAP Learning Days à lAfrican School of Economics, Abomey-Calavi, juin 2019 La présentation de la puissance statistique des EGAP Learning Days à lUniversité des Andes, Bogotá, avril 2019 La présentation de la puissance statistique des EGAP Learning Days à lUniversité catholique dUruguay, Montevideo, mars 2018 La présentation de la puissance statistique des EGAP Learning Days à Guatemala City, Guatemala, août 2017 La présentation de la puissance statistique des EGAP Learning Days à Salima, Malawi, février 2017 La présentation de la puissance statistique des EGAP Learning Days à lUniversité Diego Portales à Santiago, Chili, mai 2016 7.3 Ressources 7.3.1 Guide des méthodes EGAP Guide des méthodes EGAP 10 choses à savoir sur la puissance statistique Guide des méthodes EGAP 10 choses à savoir sur lajustement des covariables Guide des méthodes EGAP 10 choses que vos résulats non-concluants peuvent signifier 7.3.2 Notes dorientation des politiques publiques EGAP et plans de pré-analyse Quelques exemples danalyse de puissance statistique dans les designs de recherche: Plan de pré-analyse. La responsabilisation peut transformer (ACT) la santé : une réplication et une extension de Bjorkman et Svensson (2009) Note dorientation des politiques publiques EGAP 58 : La responsabilisation bottom-up peut-elle améliorer les perspectives en matière de santé ? 7.3.3 Outils Analyse de puissance statistique interactive Calculateur de puissance statistique EGAP rpsychologist Packages en R pour lanalyse de puissance statistique pwr DeclareDesign, voir aussi https://declaredesign.org/ "],["mesure.html", "Module 8 Mesure 8.1 Contenu 8.2 Slides 8.3 Ressources", " Module 8 Mesure Pour estimer les effets et tester les hypothèses, nous utilisons souvent un résultat mesuré à laide de données quantitatives provenant denquêtes, de jeux comportementaux ou darchives administratives. Pour les questions causales, nous utilisons généralement des données sur les résultats immédiats et finaux et les mécanismes de base. Nous utilisons des données de base pour identifier les sous-groupes pertinents, ajuster nos estimations ou randomiser notre traitement par bloc. Les mesures doivent être valides et fiables. Sachez que les données peuvent être bruitées (erreur aléatoire) et/ou biaisées (erreur systématique). Ce module traite que mesurer et comment mesurer. Il montre à quel point une bonne mesure est liée aux designs de recherche et à la puissance statistique. 8.1 Contenu Lorsque nous représentons un attribut dune entité par un nombre, une lettre, un mot ou un symbole dune manière systématique (par exemple, dans une case dun simple dataset), nous mesurons. Une mesure valide dun concept ou dun phénomène dintérêt doit clairement représenter cette entité sous-jacente et souvent abstraite. Une mesure fiable dun concept donnerait la même valeur pour lunité de mesure (par exemple, une personne ou un village) si les conditions nont pas changé. Nous pouvons évaluer nos théories de mesure en utilisant plusieurs approches pour mesurer les résultats, les covariables ou les différences entre unités en fonction des différents rendus des mécanismes causaux. Pour votre design de recherche, une mesure invalide peut rendre difficile la distinction efficace des explications alternatives de la relation entre le traitement et les résultats. Une mesure non fiable peut diminuer la puissance statistique. Une mesure difficile peut nécessiter une étude pilote centrée sur la mesure elle-même. 8.2 Slides Vous trouverez ci-dessous des slides avec le contenu de base de notre conférence sur la mesure. Vous pouvez les utiliser directement ou les copier localement avant de les éditer. Code source en R Markdown Version PDF Version HTML 8.3 Ressources 8.3.1 Guide des méthodes EGAP Guide des méthodes EGAP 10 choses à savoir sur la mesure dans les expériences Guide des méthodes EGAP 10 choses à savoir sur le design de questionnaire Guide des méthodes EGAP 10 choses à savoir sur limplémentation de questionnaire 8.3.2 Livres, chapitres et articles Robert Adcock and David Collier, Measurement Validity: A Shared Standard for Qualitative and Measurement Validity: A Shared Standard for Qualitative and Quantitative Research. American Political Science Review 95, no. 3 (2001): 529546. Alexandra Scacco and Shana S. Warren, Can Social Contact Reduce Prejudice and Discrimination? Evidence from a Field Experiment in Nigeria, American Political Science Review 112, no. 3 (2018): 654677. William R. Shadish et al., Experimental and Quasi-Experimental Designs for Generalized Causal Inference/William r. Shedish, Thomas d. Cook, Donald t. Campbell. (Boston: Houghton Mifflin, 2002). Pedro C. Vicente, Is Vote Buying Effective? Evidence from a Field Experiment in West Africa, Economic Journal 124, no. 574 (2014): F35687. 8.3.3 Notes dorientation des politiques publiques EGAP Grâce à des données denquête à plusieurs échelles Note dorientation des politiques publiques EGAP 58 : La responsabilisation bottom-up fonctionne-t-elle ? Grâce aux sms Note dorientation des politiques publiques EGAP 27 : Technologies de linformation et de la communication et politiciens en Uganda Note dorientation des politiques publiques EGAP 56 : Signaler la corruption au Nigéria Grâce aux données administratives Note dorientation des politiques publiques EGAP 16 : Effets de débordement des observateurs électoraux au Ghana Note dorientation des politiques publiques EGAP 67 : Administration électorale au Kenya References "],["menaces-pesant-sur-la-validité-interne-des-expériences-aléatoires.html", "Module 9 Menaces pesant sur la validité interne des expériences aléatoires 9.1 Contenu 9.2 Slides 9.3 Ressources", " Module 9 Menaces pesant sur la validité interne des expériences aléatoires Les expériences randomisées peuvent se heurter à des problèmes qui compromettent leur capacité à démontrer les effets de causalité, cest-à-dire menacer leur validité interne. Certaines unités peuvent être exclues des résultats et cette absence peut être due au traitement : soit les unités nont pas reçu le traitement qui leur était attribué ou elles ont subi des effets de débordement dun voisin traité. Dans ce module, nous abordons certaines menaces courantes et les meilleures pratiques pour les éviter ou les contourner. 9.1 Contenu Passez en revue les trois hypothèses de base discutées dans linférence causale module. Nous avons dit analysez en randomisant dans le module sur les estimandes et les estimateurs. Noubliez pas que vous avez randomisé lassignation du traitement. Vous navez pas randomisé si le traitement est reçu, ni si une unité participe à la collecte de données. Données manquantes des résultats (ie lattrition) sont particulièrement problèmatiques si le pattern des donnees absentes est causé par le traitement lui-même. Cest un problème très courant. Ne supprimez pas les observations de votre analyse pour lesquelles il manque des données. Vous pourriez borner les estimations des effets du traitement. Non-conformité. Leffet de lassignation du traitement nest pas le même que leffet reçu du traitement. Parfois, les unités ne se conformeront pas au choix de traitement qui leur a été assigné. La conformité unilatérale signifie que certaines unités assignées au traitement ne prennent pas le traitement, et toutes les unités assignées au contrôle ne prennent pas le traitement. Leffet moyen local du traitement (local average treamtent effect, LATE), aussi connu sous le nom deffet causal moyen pour ceux qui se conforment au traitement (complier average causal effect, CACE), est leffet moyen pour les unités qui prennent le traitement lorsquelles sont assignées, mais pas autrement. Si lhypothèse de monotonie et la restriction dexclusion sont remplis, il est possible destimer leffet moyen local du traitement en cas de non-conformité. Les effets de débordement ou les interférences entre unités constituent une violation de lune des hypothèses fondamentales de linférence causale (inférence causale). Cependant, cela peut ne pas être un problème si vous êtes intéressé par les effets de débordement et/ou si vous avez conçu votre recherche en en tenant compte. Leffet Hawthorne se produit lorsque les sujets se comportent différemment parce quils sont observés. La non-excluabilité. Traiter différemment les unités des groupes de traitement et de contrôle, par exemple avec des processus de collecte de données différents ou une attention particulière aux unités traitées, peut perturber linterprétation des résultats expérimentaux. Si leffet Hawthorne est présent pour le groupe de traitement mais pas pour le groupe de contrôle, il y a une violation de lhypothèse dexcluabilité. 9.2 Slides Vous trouverez ci-dessous des slides avec le contenu de base de notre conférence sur les menaces à la validité interne des expériences aléatoires. Vous pouvez les utiliser directement ou les copier localement avant de les éditer. Code source en R Markdown Version PDF Version HTML Vous pouvez également voir les slides utilisées lors des précédents EGAP Learning Days : Présentation des menaces aux EGAP Learning Days à lAfrican School of Economics, Abomey-Calavi, juin 2019 (la première section passe en revue les différents designs de randomisation) Présentation sur lattrition et les données manquantes aux EGAP Learning Days à lUniversidad Diego Portales à Santiago, Chili, mai 2016 9.3 Ressources 9.3.1 Guide des méthodes EGAP Guide des méthodes EGAP 10 choses à savoir sur les données manquantes Guide des méthodes EGAP Les 10 effets de traitement que vous devez connaître Guide des méthodes EGAP 10 choses à savoir sur leffet moyen local du traitement 9.3.2 Livres, chapitres et articles Procédures opérationnelles standard pour le laboratoire de Don Green à lUniversité de Columbia. Un ensemble complet de procédures et de règles de base pour mener des études expérimentales. Gerber and Green, Field Experiments. Chapitres 5 à 8 traitent de non-conformité, dattrition et dinterférence. 9.3.3 Note dorientation des politiques publiques EGAP Note dorientation EGAP 11 : Observateurs électoraux et fraude au Ghana Note dorientation EGAP 16 : Effets de débordement des observateurs électoraux au Ghana References "],["considérations-éthiques.html", "Module 10 Considérations éthiques 10.1 Contenu 10.2 Slides 10.3 Ressources", " Module 10 Considérations éthiques Une expérience aléatoire implique quun groupe dhumains change la vie dun autre groupe dhumains. Ceux qui travaillent pour le gouvernement le font naturellement  leur travail même est de fournir à leur peuple de la nourriture, un abri, la sécurité, la justice etc. Les universitaires, dont les travaux nont généralement pas dimpacts immédiats sur le public, doivent également se rappeler dexaminer attentivement comment leurs recherches pourraient changer la vie des personnes exposées à lintervention, ainsi que de celles qui ne lont pas été. Lorsquune personne influence la vie dune autre, linfluenceur a la responsabilité de ne pas nuire à la personne influencée. Ce module traite des sujets de base sur léthique de la recherche, tels que la vie privée et lautonomie ; les principes de base comme le respect des personnes, la bienveillance et la justice ; et comment le consentement éclairé aide à communiquer ces principes aux participants de létude. 10.1 Contenu La recherche doit peser les bénéfices potentiels des connaissances à tirer de la recherche par rapport aux dommages potentiels quelle peut causer aux sujets humains. Que ressentiriez-vous si vous étiez un sujet de recherche dans votre étude ? Dans le groupe contrôle ? Dans le groupe de traitement ? Un membre de statut relativement élevé dans la communauté ? Un membre de statut relativement bas dans la communauté ? Principes clés : la confidentialité et lautonomie. Principes de base du rapport Belmont : respect des personnes, bienveillance, justice. Consentement éclairé : Pouvez-vous garantir que les sujets de recherche ont la liberté de refuser de participer et/ou dabandonner létude sils le souhaitent ? Pouvez-vous vous assurer que les sujets de recherche peuvent signaler les problèmes qui pourraient survenir ? Défis de la recherche expérimentale en sciences sociales en général: Beaucoup plus de personnes peuvent profiter (ou souffrir) de votre intervention que ceux participant directement à votre étude Modifier les résultats des élections ou changer la corruption peuvent entraîner de grands changements sociétaux. Est-ce aller au-delà du domaine de la recherche ? 10.2 Slides Vous trouverez ci-dessous des slides avec le contenu de base pour cette section. Code source en R Markdown Version PDF Version HTML 10.3 Ressources Principes de recherche et travaux sur léthique de EGAP Principes et lignes directrices pour la recherche sur des sujets humains de APSA Le rapport Belmont Les comités de revue éthique institutionnels aux US Exemple : Éthique de la recherche à lUniversité dOxford au Royaume-Uni Exemple : Éthique pour les chercheurs dans lUE Exemple : Éthique de la recherche à lUniversité catholique du Chile 10.3.1 Livres, chapitres et articles Edward Asiedu et al., A Call for Structured Ethics Appendices in Social Science Papers, Working Paper, Working Paper Series (National Bureau of Economic Research, 2021), doi:10.3386/w28393. David K. Evans, Towards Improved and More Transparent Ethics in Randomised Controlled Trials in Development Social Science, Working Paper (Center for Global Development, 2021), https://www.cgdev.org/sites/default/files/WP565-Evans-Ethical-issues-and-RCTs.pdf. 10.3.2 Articles et plans de pré-analyse Exemples de plans de pré-analyse et darticles sur les considérations éthiques: Plan de pré-analyse : les effets des bons non-alimentaires dans un contexte humanitaire, le cas du programme de réponse rapide aux mouvements de population au Congo Article : Appendix E.1 Lutter contre la violence à légard des femmes en encourageant la dénonciation : une expérience dans les médias de masse en Ouganda rural References "],["glossaire-des-termes.html", "A Glossaire des termes A.1 Key Concepts A.2 Statistical Inference A.3 Randomization Strategies A.4 Factorial Designs A.5 Threats", " A Glossaire des termes Ci-dessous voici les termes principaux, fréquemment utilisés dans le livre et plus généralement à travers les discussions dexpériences de terrain aléatoires. A.1 Key Concepts See the module on causal inference, estimands and estimators. Potential outcome \\(Y_i(T)\\) The outcome \\(Y\\) that unit \\(i\\) would have under treatment condition \\(T\\). We think of these as fixed quantities for a specific point in time. \\(T\\) can be 0 for control or 1 for treatment if there is only one type of treatment. See the module on causal inference. Treatment effect \\(\\tau_i\\) for unit \\(i\\) The contrast between potential outcomes under two treatment conditions for unit \\(i\\). We typically define the treatment effect as the difference in potential outcomes under treatment and control, \\(Y_i(1)-Y_i(0)\\). See the module on causal inference. Fundamental problem of causal inference in the counterfactual framework. We cant observe both \\(Y_i(1)\\) and \\(Y_i(0)\\) for a given unit, so we cant get \\(\\tau_i\\) directly. See the module on causal inference. Estimand The thing you want to estimate. An example of an estimand is the average treatment effect. In counterfactual causal inference, this is a function of potential outcomes, not fully observed outcomes. See the module on estimands and estimators. Estimator How you make a guess about the value of your estimand from the data you have (i.e., observed). An example of an estimator is the difference-in-means. See the module on estimands and estimators. Average treatment effect, ATE The average of the treatment effect for all individuals in your subject pool. This is a type of estimand. If we define \\(\\tau_i\\) to be \\(Y_i(1)-Y_i(0)\\), then the ATE is \\(\\overline{Y_i(1)-Y_i(0)}\\), which is also equivalent to \\(\\overline{{Y}_i(1)}-\\overline{{Y}_i(0)}\\). Notice that we do not use the \\(E[Y_i (1)]\\) style of notation here because \\(E[]\\) means average over repeated operations, but \\(\\overline{Y}\\) means average over a set of observations. See the module on causal inference and the module on estimands and estimators. Random sampling Selecting subjects from a population with known probabilities strictly between 0 and 1. \\(k\\)-arm experiment An experiment that has \\(k\\) treatment conditions (including control). See the module on randomization. Random assignment Assigning subjects to experimental conditions with known probabilities strictly between 0 and 1. This is equivalent to random sampling without replacement from the potential outcomes. There are several strategies for random assignment: simple, complete, cluster, block, blocked-cluster. See the module on randomization. External validity Findings from your study teach you about contexts outside of your sample  in other locations or for other interventions. A.2 Statistical Inference See modules on hypothesis testing and statistical power. Hypothesis A simple, clear, falsifiable claim about the world. In counterfactual causal inference, this is a statement about a relationship among potential outcomes, like \\(H_0: Y_i(T_i=0) = Y_i(T_i=1) + \\tau_i\\) for the hypothesis that the potential outcome under treatment is the potential outcome under control plus some effect for each unit \\(i\\). See the module on hypothesis testing. Null hypothesis A conjecture about the world that you may reject after seeing the data. See the module on hypothesis testing. Sharp null hypothesis of no effect The null hypothesis that there is no treatment effect for any subject. This means \\(Y_i(1)=Y_i(0)\\) for all \\(i\\). We might write this as \\(H_0: Y_i(T_i=0) = Y_i(T_i=1)\\). See the module on hypothesis testing. \\(p\\)-value The probability of seeing a test statistic as large (in absolute value) as or larger than the test statistic calculated from observed data. See the module on hypothesis testing. One-sided vs. two-sided test When you have a strong expectation that the effect is either positive or negative, you can conduct a one-sided test. When you do not have such a strong expectation, conduct a two-sided test. A one-sided test has more power than a two-sided test for the same experiment. See the module on hypothesis testing. Standard deviation Square root of the mean-square deviation from the average of a variable. It is a measure of the dispersion or spread of a statistic. \\(SD_x=\\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})^2}\\) False Positive Rate/Type I Error of a Test A well-operating hypothesis test rejects a hypothesis about a true causal effect no more than \\(\\alpha\\) % of the time. The false positive rate is the rate at which a test will cast doubt on a true hypothesis. It is the rate at which the test will encourage the analyst to say statistically significant when, in fact, there is no causal relationship. See the module on hypothesis testing. Sampling distribution The distribution of estimates (e.g., estimates of the ATE) for all possible treatment assignments. In design-based statistical inference for randomized experiments, the distribution of estimates from an estimator is generated from randomizations. Many call this a sampling distribution because textbooks often use the idea of repeated samples from a population rather than repeated randomizations to describe this kind of variation. Standard error The standard deviation of the sampling distribution. A bigger standard error means that our estimates are more susceptible to sampling variation. See the module on estimands and estimators. Coverage of a confidence interval A well-operating confidence interval contains the true causal effect \\(100 ( 1 - \\alpha)\\) % of the time. A confidence interval has incorrect coverage when it excludes the true parameter less than \\(100 (1 - \\alpha)\\)% of the time. For example, a 95% confidence interval is supposed to only exclude the true parameter less than 5% of the time. Statistical power of a test Probability that a test of causal effects will detect a statistically significant treatment effect if the effect exists. See the module on statistical power. This depends on: The number of observations in each arm of the experiment Effect size (usually measured in standardized units) Noisiness of the outcome variable Significance level (\\(\\alpha\\), which is fixed by convention) Other factors including what proportion of your units are assigned to different treatment conditions. Intra-cluster correlation How correlated the potential outcomes of units are within clusters compared to across clusters. Higher intra-cluster correlation hurts power. Unbiased An estimator is unbiased if you expect that it will return the right outcome. That means that if you were to run the experiment many times, the estimate might be too high or to low sometimes but it will be right on average. See the module on estimands and estimators. Bias Bias is the difference between the average value of the estimator across its sampling distribution and the single, fixed value of the estimand. See the module on estimands and estimators. Consistency of an estimator An estimator that produces answers that become ever nearer to the true value of the estimand as the sample size increases is a consistent estimator of that estimand. A consistent estimator may or may not be unbiased. See the module on estimands and estimators. Precision/Efficiency of an estimator The variation in or width of the sampling distribution of an estimator. See the module on estimands and estimators. A.3 Randomization Strategies See the module on randomization. Simple An independent coin flip for each unit. You are not guaranteed that your experiment will have a specific number of treated units. Complete Assign \\(m\\) out of \\(N\\) units to treatment. You know how many units will be treated in your experiment and each unit has a \\(m/N\\) probability of being treated. The number of ways treatment can be assigned (number of permutations of treatment assignment) is \\(\\frac{N!}{m!(N-m)!}\\). Block First divide the sample into blocks, then do complete randomization separately in each block. A block is a set of units within which you conduct random assignment. Cluster Clusters of units are randomly assigned to treatment conditions. A cluster is a set of units that will always be assigned to the same treatment status. Blocked-Cluster First form blocks of clusters. Then in each block, randomly assign the clusters to treatment conditions using complete randomization. A.4 Factorial Designs See the module on randomization. Factorial design A design with more than one treatment, with each treatment assigned independently. The simplest factorial design is a 2 by 2. Conditional marginal effect The effect of one treatment, conditional on the other being held at a fixed value. For example: \\(Y_i(T_1=1|T_2=0)-Y_i(T_1=0|T_2=0)\\) is the marginal effect of \\(T_1\\) conditional on \\(T_2=0\\). Average marginal effect Main effect of each treatment in a factorial design. It is the average of the conditional marginal effects for all the conditions of the other treatment, weighted by the proportion of the sample that was assigned to each condition. Interaction effect In a factorial design, we may also estimate interaction effects. No interaction effect: one treatment does not amplify or reduce the effect of the other treatment. Multiplicative interaction effect: the effect of one treatment depends on which condition a unit was assigned for the other treatment. This means one treatment does amplify or reduce the effect of the other. The effect of two treatments together is not the sum of the effect of each treatment. A.5 Threats See the module on threats. Hawthorne effect When a subject responds to being observed. Spillover When a subject responds to another subjects treatment status. Example: my health depends on whether my neighbor is vaccinated, as well as whether I am vaccinated. Attrition When outcomes for some subjects are not measured. This might be caused, for example, by people migrating, refusing to respond to endline surveys, or dying. This is especially problematic for inference when it is correlated with treatment status. Compliance A units treatment status matches its assigned treatment condition. Example of non-compliance: a unit assigned to treatment doesnt take it. Example of compliance: a unit assigned to control does not take treatment. Compliance types There are four types of units in terms of compliance: Compliers Units that would take treatment if assigned to treatment and would be untreated if assigned to control. Always-takers Units that would take treatment if assigned to treatment and if assigned to control. Never-takers Units that would be untreated if assigned to treatment and if assigned to control. Defiers Units that would be untreated if assigned to treatment and would take treatment if assigned to control. One-sided non-compliance The experiment has only compliers and either always-takers or never-takers. Usually, we think of one-sided non-compliance as having only never-takers and compliers, meaning that that local average treatment effect is the effect of treatment on the treated. Two-sided non-compliance The experiment may have all four latent groups. Encouragement design An experiment that randomizes \\(T\\) (treatment assignment), and we measure \\(D\\) (whether the unit takes treatment) and \\(Y\\) (outcome). We can estimate the ITT and the LATE (local average treatment effect, aka CACEcomplier average causal effect). It requires three assumptions. Monotonicity Assumption of either no defiers or no compliers. Usually we assume no defiers which means that the effect of assignment on take up of treatment is either positive or zero but not negative. First stage Assumption that there is an effect of \\(T\\) on \\(D\\). Exclusion restriction Assumption that \\(T\\) affects \\(Y\\) only through \\(D\\). This is usually the most problematic assumption. Intention-to-treat effect (ITT) The effect of \\(T\\) (treatment assignment) on \\(Y\\). Local average treatment effect (LATE) The effect of \\(D\\) (taking treatment) on \\(Y\\) for compliers. Also known as the complier average causal effect (CACE). Under the exclusion restriction and monotonicity, the LATE is equal to ITT divided by the proportion of your sample who are compliers. Downstream experiment An encouragement design study that takes advantage of the randomization of \\(T\\) by a previous study. The outcome from that previous study is the \\(D\\) in the downstream experiment. "],["introduction-à-r-et-rstudio.html", "B Introduction à R et RStudio B.1 R et RStudio B.2 Télécharger R et RStudio B.3 Linterface RStudio B.4 Apprendre à utiliser R", " B Introduction à R et RStudio Tout au long du livre, nous incluons du code R pour lestimation, la simulation et la création dexemples. Nous avons utilisé RStudio pour créer les slides. Pour les personnaliser à vos propres fins, nous supposons que vous utiliserez R Markdown. Ci-dessous, voici les guides pour configurer R et RStudio sur votre machine, ainsi que quelques commandes de base fréquemment utilisées. B.1 R et RStudio R est un environnement logiciel libre utilisé couramment pour lanalyse statistique et le calcul. Étant donné que les participants aux Learning Days arrivent avec un bagage statistique et des outils différents, nous utilisons R pour nous assurer que tout le monde se comprend. Nous recommendons lutilisation de R de manière générale pour sa flexibilité, sa richesse et son support complet, principalement via des forums en ligne. RStudio est un environnement de développement intégré gratuit et open source avec une interface utilisateur qui rend R beaucoup plus convivial. R Markdown est une fonctionnalité de RStudio qui permet de présenter facilement du code, des résultats et du texte au format .pdf, .html ou .doc. B.2 Télécharger R et RStudio B.2.1 Télécharger R R est téléchargeable gratuitement sur CRAN au lien correspondant à votre système dexploitation: Pour Windows : https://cran.r-project.org/bin/windows/base/ Pour Mac OS X : https://cran.r-project.org/bin/macosx/. Sélectionner R-4.0.4.pkg pour OS X 10.13 et plus. Sélectionner R-3.6.3.nnpkg pour OS X 10.11-10.12. Sélectionner R-3.3.3.nnpkg pour OS X 10.19-10.10. Sélectionner R-3.2.1-snowleopard.pkg pour OS X 10.6-10.8. B.2.2 Télécharger RStudio RStudio peut être téléchargé gratuitement sur le site Web de RStudio, https://www.rstudio.com/products/rstudio/download/. Dans le tableau, cliquez sur le bouton bleu Download en haut de la colonne de gauche, Licence Open Source RStudio Desktop, comme illustré ci-dessous dans la figure B.1. Après avoir cliqué, vous verrez une liste doptions de téléchargement, comme illustré à la Figure B.2. Pour Windows, sélectionner Windows 10/8/7. Pour Mac OS X, sélectionner Mac OS X 10.13+. Figure B.1: Sélectionner Download dans la colonne RStudio Desktop Open Source License. Figure B.2: Sélectionner le lien Windows 10/8/7 pour Windows ou Mac OS X 10.13+ pour Mac. B.3 Linterface RStudio Lorsque vous ouvrez RStudio pour la première fois, trois onglets doivent être visibles, comme illustré dans la Figure B.3 ci-dessous. Console (à gauche) Accounting (en haut à droite) : cela inclue les onglets Environment et History Miscellaneous (en bas à droite) Figure B.3: Lorsque vous ouvrez RStudio, il y a trois panneaux visibles : la Console (à gauche), Accounting (en haut à droite), et Miscellaneous (en bas à droite). B.3.1 La console Vous pouvez exécuter toutes les opérations dans la console. Par exemple, si vous saisissez 4 + 4 et appuyez sur la touche Enter, la console renvoie [1] 8. Pour sassurer que tout le monde est prêt à utiliser R lors des Learning Days, nous demandons aux participants dexécuter une ligne de code dans la console pour télécharger plusieurs packages R. Les packages sont des fragments de code reproducibles qui permettent une analyse plus efficace dans R. Pour exécuter ce bout de code, copiez-le dans la console et appuyez sur votre touche Enter. Vous devez être connecté à internet pour télécharger des packages. install.packages(c(&quot;ggplot2&quot;, &quot;dplyr&quot;, &quot;AER&quot;, &quot;arm&quot;, &quot;MASS&quot;, &quot;sandwich&quot;, &quot;lmtest&quot;, &quot;estimatr&quot;,&quot;coin&quot;,&quot;randomizr&quot;, &quot;DeclareDesign&quot;)) Si le téléchargement est réussi, votre console ressemblera à la figure B.4, sauf que les URL seront différentes en fonction de votre emplacement. Figure B.4: La console après avoir exécuté les trois lignes de code répertoriées ci-dessus. B.3.2 Léditeur Afin décrire et sauvegarder du code reproductible, nous allons ouvrir un quatrième panneau, léditeur, en cliquant sur licône avec une page blanche et un signe plus, dans le coin supérieur gauche de linterface RStudio et en sélectionnant R Script, comme illustré à la figure B.5. Figure B.5: Créez un nouveau script R et ouvrez le panneau éditeur en sélectionnant R Script dans le menu déroulant. Une fois le script R ouvert, il devrait y avoir quatre panneaux dans linterface RStudio, maintenant avec lajout du panneau Éditeur. Nous pouvons exécuter une arithmétique simple en entrant une formule dans léditeur et en appuyant sur Ctrl + Entrée (Windows) ou Commande + Entrée (Mac). La formule et la réponse apparaîtront dans la console, comme illustré à la Figure B.6. Figure B.6: Une expression arithmétique est saisie dans léditeur et évaluée dans la console. Les cases rouges sont ajoutées pour une visibilité accrue. R peut être utilisé pour toute opération arithmétique, y compris, mais sans sy limiter, laddition (+), la soustraction (-), la multiplication scalaire (*), la division (/) et lexponentielle (^ ). B.3.3 Gestion Au-delà des fonctions de base, nous pouvons également stocker des valeurs, des données et des fonctions dans lenvironnement global. Pour affecter une valeur à une variable, utilisez lopérateur &lt;-. Toutes les valeurs, fonctions et données stockées apparaîtront dans longlet Environnement du panneau Gestion. Dans la Figure B.7, nous définissons la variable t pour prendre la valeur \\(3 \\times \\frac{6}{14}\\), et pouvons voir quelle est stockée sous Valeurs. Nous chargeons également un jeu de données. Ici, ChickWeight est un dataset intégré à R ; la plupart des datasets seront chargés à partir du Web ou dautres fichiers sur votre ordinateur via une autre méthode. Nous pouvons voir que ChickWeight contient 578 observations de 4 variables et est stocké dans lEnvironnement. En cliquant sur le nom ChickWeight, un onglet souvrira avec le dataset dans la fenêtre de votre éditeur. Figure B.7: La valeur 3 * (6/14) est attribuée à la variable t (en rouge) et le dataset ChickWeight est ajouté à lenvironnement global (en bleu). Les workshops Learning Days utilisent de nombreux outils dans R pour analyser et visualiser les données. Pour linstant, nous pouvons apprendre quelques outils de base pour examiner les données. La fonction head() nous permet de voir les six premières lignes des données. summary() résume chacune des colonnes du dataset et dim() fournit les dimensions du dataset avec dabord le nombre de lignes puis de colonnes. head(ChickWeight) # Les 6 premières observations du dataset weight Time Chick Diet 1 42 0 1 1 2 51 2 1 1 3 59 4 1 1 4 64 6 1 1 5 76 8 1 1 6 93 10 1 1 summary(ChickWeight) # Résumé de toutes les variables weight Time Chick Diet Min. : 35 Min. : 0.0 13 : 12 1:220 1st Qu.: 63 1st Qu.: 4.0 9 : 12 2:120 Median :103 Median :10.0 20 : 12 3:120 Mean :122 Mean :10.7 10 : 12 4:118 3rd Qu.:164 3rd Qu.:16.0 17 : 12 Max. :373 Max. :21.0 19 : 12 (Other):506 dim(ChickWeight) # Dimensions du dataset dans l&#39;ordre lignes puis colonnes [1] 578 4 Contrairement à dautres logiciels statistiques, R permet aux utilisateurs de stocker simultanément plusieurs ensembles de données, éventuellement de dimensions différentes. Cette fonctionnalité rend R assez flexible pour lanalyse à laide de plusieurs méthodes. B.3.4 Divers R fournit une suite doutils, allant des fonctions intégrées aux packages pour tracer graphiques, modèles, estimations, etc. Le dernier panneau Divers permet une visualisation rapide des graphiques dans RStudio. La Figure B.8 montre une courbe dans ce panneau. Pendant les Leaning Days, on discutera de la manière de tracer les données. Figure B.8: Un exemple de courbe avec le dataset ChickWeight en R. B.4 Apprendre à utiliser R B.4.1 Ressources en ligne Il existe de nombreuses ressources en ligne utiles pour vous aider à commencer à apprendre R. Nous vous recommandons deux sources : Code School, qui fonctionne entièrement sur votre navigateur https://www.codeschool.com/courses/try-r. Coursera, via un cours de programmation R en ligne organisé par lUniversité Johns Hopkins: Allez sur https://www.coursera.org Créez un compte (cest gratuit!) Inscrivez-vous pour R Programming at Johns Hopkins University (instructeur : Roger Peng) sous la rubrique Cours Lisez les documents et regardez les vidéos de la première semaine. Les vidéos de la première semaine durent environ 2 heures 30 au total. B.4.2 Exercise de base Voici quelques fragments de code pour vous familiariser avec certaines pratiques de base de R. Nous vous recommandons de vous entraîner en tapant les fragments de code dans votre éditeur, puis en les évaluant. B.4.2.1 Configuration dune session R En général, nous lisons dautres fichiers tels que des données ou des fonctions dans R et publions des résultats tels que des graphiques ou des tableaux dans des fichiers en dehors de la session R. Pour ce faire, nous devons donner à R une adresse où il peut localiser de tels fichiers. Il peut être plus efficace de le faire en définissant un répertoire de travail, ie un chemin daccès au répertoire dans lequel les fichiers pertinents sont stockés. Nous pouvons identifier le répertoire de travail actuel en utilisant getwd() et le définir en utilisant setwd(). Notez que la syntaxe de ces chemins de fichiers varie selon le système dexploitation. getwd() setwd(&quot;~TaraLyn/EGAP Learning Days Admin/Workshop 2018_2 (Uruguay)/&quot;) Vous devrez peut-être installer des packages autres que ceux répertoriés ci-dessus pour exécuter certaines fonctions. Pour installer les packages, nous utilisons install.packages(\"\"), en remplissant le nom du package entre les marques \"\", comme suit. Vous navez besoin dinstaller les packages quune seule fois. install.packages(&quot;randomizr&quot;) Une fois quun package est installé, il peut être chargé et accessible en utilisant library() où le nom du package est inséré entre parenthèses (sans guillemets). library(randomizr) Pour effacer de la mémoire de R, les données, fonctions ou valeurs stockées qui apparaissent dans longlet de comptabilité, utilisez rm(list = ls()). Il peut être utile de définir un nombre aléatoire pour garantir que la réplication est possible dans une session R différente, en particulier lorsque nous travaillons avec des méthodes basées sur la simulation. rm(list = ls()) set.seed(2018) # pour la reproductibilité B.4.2.2 Les basics Nous allons maintenant explorer quelques commandes de base. Afin daffecter un scalaire (ie un élément unique) à une variable, nous utilisons la commande &lt;- comme discuté précédemment: # &quot;&lt;-&quot; est la commande d&#39;affectation ; ça sert à définir les choses. eg: (a &lt;- 5) [1] 5 Nous pouvons également vouloir affecter un vecteur déléments à une variable. Ici, nous utilisons la même commande &lt;-, mais nous nous concentrons sur la façon de créer le vecteur. (b &lt;- 1:10) # &quot;:&quot; est utilisé pour définir une chaîne d&#39;entiers [1] 1 2 3 4 5 6 7 8 9 10 (v &lt;- c(1, 3, 2, 4, pi)) # utilisez c() pour faire un vecteur avec n&#39;importe quoi dedans [1] 1.000 3.000 2.000 4.000 3.142 On peut alors se référer aux éléments dun vecteur en désignant leur position à lintérieur de parenthèses []. # Extract elements of a vector: b[1] # Retourne la position 1 [1] 1 b[5:4] # Retourne les positions 5 et 4, dans cet ordre [1] 5 4 b[-1] # Retourne tout sauf le premier élément [1] 2 3 4 5 6 7 8 9 10 # Retourne tous les nombres indiqués comme &quot;TRUE&quot; b[c(TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE)] [1] 1 3 6 7 # Attribue une nouvelle valeur aux éléments particuliers d&#39;un vecteur b[5] &lt;- 0 Il existe un ensemble de fonctions pré-existantes qui peuvent être appliquées à des vecteurs comme b. sum(b) # Somme de tous les éléments [1] 50 mean(b) # Moyenne de tous les éléments [1] 5 max(b) # Maximum de tous les éléments [1] 10 min(b) # Minimum de tous les éléments [1] 0 sd(b) # Écart type de tous les éléments [1] 3.496 var(b) # Variance de tous les éléments [1] 12.22 On peut aussi appliquer des transformations arithmétiques à tous les éléments dun vecteur: b^2 # Carré de la variable [1] 1 4 9 16 0 36 49 64 81 100 b^.5 # Racine carré de la variable [1] 1.000 1.414 1.732 2.000 0.000 2.449 2.646 2.828 3.000 3.162 log(b) # Log de la variable [1] 0.0000 0.6931 1.0986 1.3863 -Inf 1.7918 1.9459 2.0794 2.1972 2.3026 exp(b) # Exponentielle de la variable [1] 2.718 7.389 20.086 54.598 1.000 403.429 1096.633 2980.958 8103.084 22026.466 Enfin, nous pouvons évaluer les affirmations logiques (cest-à-dire « la condition X est-elle vraie ? ») sur tous les éléments dun vecteur: b == 2 # égal à [1] FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE b &lt; 5 # plus petit que [1] TRUE TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE b &gt;= 5 # plus petit ou égal à [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE b &lt;= 5 | b / 4 == 2 # | signifie OU [1] TRUE TRUE TRUE TRUE TRUE FALSE FALSE TRUE FALSE FALSE b&gt;2 &amp; b&lt;9 # &amp; signifie ET [1] FALSE FALSE TRUE TRUE FALSE TRUE TRUE TRUE FALSE FALSE is.na(b) # Indique si la donnée est manquante [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE which(b&lt;5) # Donne les indices des éléments dont la valeur répond à la condition [1] 1 2 3 4 5 La logique de base de ces commandes sapplique à des structures de données beaucoup plus complexes que les scalaires et les vecteurs. La compréhension de ces fonctionnalités de base vous aidera à mieux comprendre des sujets avancés au cours des Learning Days. "],["réferences.html", "Réferences", " Réferences "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
